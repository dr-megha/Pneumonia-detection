{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Chest_x_ray\n",
    "import torch\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = Chest_x_ray.ConvolutionalNetwork()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_checkpoint = \"checkpoints_xrays/train_loss_0.49879632698246307_val_loss_0.6052662283182144.pt\"\n",
    "model = load_model(best_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalNetwork(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=1032256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (fc3): Linear(in_features=60, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/data/analytics/naveen.bansal/Jeremy/data/chest_xray/\")\n",
    "test_data_path = path/'test'\n",
    "test_imgs,test_labels = Chest_x_ray.load_data(test_data_path)\n",
    "test_labels = Chest_x_ray.map_labels(test_labels)\n",
    "test_dataset=Chest_x_ray.CNN_Dataset(test_imgs, test_labels)\n",
    "test_dataloader= torch.utils.data.DataLoader(test_dataset, batch_size = 5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metric(li_y_true,li_y_pred):   \n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    li=zip(li_y_true,li_y_pred)\n",
    "    for item in li:\n",
    "        true=item[0]\n",
    "        pred=item[1]\n",
    "        ground_truth=[it[0] for it in true]\n",
    "        prediction=[it[0] for it in pred]\n",
    "        for g,p in zip(prediction,ground_truth):\n",
    "            if g==1 and p==1:\n",
    "                TP=TP+1\n",
    "            if g==0 and p==1:\n",
    "                FP=FP+1\n",
    "            if g==1 and p==0:\n",
    "                FN=FN+1\n",
    "            if g==0 and p==0:\n",
    "                TN=TN+1\n",
    "    accuracy=(TP+TN)/len(test_labels)\n",
    "    recall=TP/(TP+FN)\n",
    "    precision=TP/(TP+FP)\n",
    "    F1score=2*((precision*recall)/(precision+recall))\n",
    "    return accuracy, recall,precision,F1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.6987179487179487, Recall: 0.6753472222222222, Precision: 0.9974358974358974, F1 score: 0.805383022774327\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "li_y_pred=[]\n",
    "li_y_true=[]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "for batch in test_dataloader:\n",
    "        x=batch[0]\n",
    "        y_true=batch[1]\n",
    "               \n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y_true  = y_true.cuda()\n",
    "            \n",
    "        y_pred=model.forward(x)\n",
    "        y_pred=torch.argmax(y_pred,dim=1).reshape(-1,1).tolist()\n",
    "        y_true=y_true.tolist()\n",
    "        li_y_true.append(y_true)\n",
    "        li_y_pred.append(y_pred)    \n",
    "accuracy, recall,precision,F1score=model_metric(li_y_true,li_y_pred)\n",
    "print (f\" Accuracy: {accuracy}, Recall: {recall}, Precision: {precision}, F1 score: {F1score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import datasets,transforms\n",
    "import pdb\n",
    "\n",
    "def predict(model,img_path):\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    trans=transforms.Compose([transforms.Resize(1024), \n",
    "                                  transforms.CenterCrop(1023), \n",
    "                                  transforms.Grayscale(num_output_channels=1), \n",
    "                                  transforms.ToTensor()])\n",
    "    x=trans(img)\n",
    "    if torch.cuda.is_available():\n",
    "        x= x[None,:,:,:].cuda() \n",
    "    pred = model.forward(x)\n",
    "    predicted_class = torch.argmax(pred).item()\n",
    "    if predicted_class==0:\n",
    "        predicted_class =  \"Normal\"\n",
    "    else:\n",
    "        predicted_class =  \"Pneumonia\"\n",
    "    \n",
    "    return predicted_class\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Pneumonia\n"
     ]
    }
   ],
   "source": [
    "prediction=predict(model, \"/data/analytics/naveen.bansal/Jeremy/data/chest_xray/test/PNEUMONIA/person10_virus_35.jpeg\")\n",
    "print (f\"Predicted Class: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
